{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3yuknghXL6/8HJ5iyEyWe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliTavakoli2001/Deep-Learning-Project/blob/main/Persian_text_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hCE5pM330wrh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sample data"
      ],
      "metadata": {
        "id": "F72sJpQz1e8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"بسی رنج بردم در این سال سی\",\n",
        "    \"عجم زنده کردم بدین پارسی\",\n",
        "    \"جهان را بپرسید از این داستان\",\n",
        "    \"که نامش بماند همیشه به سان\"\n",
        "]"
      ],
      "metadata": {
        "id": "kflC9v131hJn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting text to digits"
      ],
      "metadata": {
        "id": "ih2EhXW31lxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "max_len = max(len(seq) for seq in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "qn9pJvba1ivs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating model"
      ],
      "metadata": {
        "id": "VcrBMo3t1w4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder model**"
      ],
      "metadata": {
        "id": "5qgCDDUM5UOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 128  # افزایش ظرفیت فشرده‌سازی\n",
        "inputs = Input(shape=(max_len,))\n",
        "embedding = Embedding(vocab_size, 256, input_length=max_len)(inputs)\n",
        "encoded = LSTM(latent_dim, return_state=True, dropout=0.3, recurrent_dropout=0.3)\n",
        "encoder_outputs, state_h, state_c = encoded(embedding)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpnrv6R55S-m",
        "outputId": "f39c50ae-7a19-4d65-9061-e96cb4959ee6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder model**"
      ],
      "metadata": {
        "id": "GcuLl8cv5cH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(max_len,))\n",
        "decoder_embedding = Embedding(vocab_size, 256, input_length=max_len)(decoder_inputs)\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.3, recurrent_dropout=0.3)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "decoder_dense = Dense(vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "id": "mJqrn3Jv5es1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seq2Seq model and compiling**"
      ],
      "metadata": {
        "id": "L3nbRLbQ5k95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fn0sM5085rng"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prepare data"
      ],
      "metadata": {
        "id": "BeGRNoNC2awZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_sequences = np.array(sequences)"
      ],
      "metadata": {
        "id": "GRqpKrGB2aFJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train model"
      ],
      "metadata": {
        "id": "z10vyTsM2nKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([sequences, sequences], target_sequences, epochs=100, batch_size=16, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXM2XKGX2kP5",
        "outputId": "c5a6673f-b9ba-49aa-be21-08aab93238d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step - accuracy: 0.1190 - loss: 2.9399 - val_accuracy: 0.2500 - val_loss: 2.9344\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.2738 - loss: 2.9227 - val_accuracy: 0.2500 - val_loss: 2.9228\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.3333 - loss: 2.8992 - val_accuracy: 0.2500 - val_loss: 2.9108\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.3214 - loss: 2.8742 - val_accuracy: 0.2143 - val_loss: 2.8979\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.3333 - loss: 2.8483 - val_accuracy: 0.2143 - val_loss: 2.8836\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.2619 - loss: 2.8177 - val_accuracy: 0.1786 - val_loss: 2.8675\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.2500 - loss: 2.7881 - val_accuracy: 0.1786 - val_loss: 2.8491\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.1905 - loss: 2.7444 - val_accuracy: 0.1786 - val_loss: 2.8280\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.2024 - loss: 2.6777 - val_accuracy: 0.1786 - val_loss: 2.8052\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.1905 - loss: 2.6146 - val_accuracy: 0.1786 - val_loss: 2.7935\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.1905 - loss: 2.5334 - val_accuracy: 0.1786 - val_loss: 2.8410\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.1905 - loss: 2.4616 - val_accuracy: 0.1786 - val_loss: 2.9371\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.1905 - loss: 2.4484 - val_accuracy: 0.1786 - val_loss: 2.9962\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 318ms/step - accuracy: 0.1905 - loss: 2.3931 - val_accuracy: 0.1786 - val_loss: 3.0033\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 0.2262 - loss: 2.3842 - val_accuracy: 0.2143 - val_loss: 2.9794\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.2976 - loss: 2.3013 - val_accuracy: 0.1786 - val_loss: 2.9503\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.2857 - loss: 2.3121 - val_accuracy: 0.1786 - val_loss: 2.9096\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.2857 - loss: 2.2570 - val_accuracy: 0.1786 - val_loss: 2.8633\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.3214 - loss: 2.2397 - val_accuracy: 0.2143 - val_loss: 2.8095\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 0.3690 - loss: 2.1936 - val_accuracy: 0.2857 - val_loss: 2.7604\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3929 - loss: 2.1569 - val_accuracy: 0.2857 - val_loss: 2.7243\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.4167 - loss: 2.1511 - val_accuracy: 0.2857 - val_loss: 2.6935\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.3810 - loss: 2.1298 - val_accuracy: 0.2857 - val_loss: 2.6684\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.4286 - loss: 2.1020 - val_accuracy: 0.2857 - val_loss: 2.6523\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.4048 - loss: 2.0732 - val_accuracy: 0.3214 - val_loss: 2.6492\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.4167 - loss: 2.0103 - val_accuracy: 0.2143 - val_loss: 2.6583\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.3452 - loss: 2.0024 - val_accuracy: 0.2143 - val_loss: 2.6656\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.4286 - loss: 1.9538 - val_accuracy: 0.2500 - val_loss: 2.6588\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462ms/step - accuracy: 0.4048 - loss: 1.9189 - val_accuracy: 0.2857 - val_loss: 2.6441\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 722ms/step - accuracy: 0.4524 - loss: 1.8592 - val_accuracy: 0.3214 - val_loss: 2.6299\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.4643 - loss: 1.8263 - val_accuracy: 0.3214 - val_loss: 2.6128\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.4524 - loss: 1.8152 - val_accuracy: 0.3214 - val_loss: 2.5933\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.4762 - loss: 1.7923 - val_accuracy: 0.3214 - val_loss: 2.5709\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4524 - loss: 1.7754 - val_accuracy: 0.3571 - val_loss: 2.5396\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step - accuracy: 0.5238 - loss: 1.7589 - val_accuracy: 0.4286 - val_loss: 2.5155\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.5357 - loss: 1.6886 - val_accuracy: 0.4286 - val_loss: 2.4961\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.5952 - loss: 1.6117 - val_accuracy: 0.4286 - val_loss: 2.4789\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.5714 - loss: 1.6125 - val_accuracy: 0.4286 - val_loss: 2.4420\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.6190 - loss: 1.5722 - val_accuracy: 0.5000 - val_loss: 2.4007\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.5833 - loss: 1.5271 - val_accuracy: 0.5000 - val_loss: 2.3649\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.6667 - loss: 1.4559 - val_accuracy: 0.5357 - val_loss: 2.3300\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.6071 - loss: 1.4476 - val_accuracy: 0.5357 - val_loss: 2.3016\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.6429 - loss: 1.3912 - val_accuracy: 0.5357 - val_loss: 2.2837\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.6667 - loss: 1.3621 - val_accuracy: 0.5357 - val_loss: 2.2679\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.6786 - loss: 1.3288 - val_accuracy: 0.5357 - val_loss: 2.2549\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.7262 - loss: 1.2309 - val_accuracy: 0.5357 - val_loss: 2.2395\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7381 - loss: 1.2068 - val_accuracy: 0.5714 - val_loss: 2.2200\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.7262 - loss: 1.2002 - val_accuracy: 0.5714 - val_loss: 2.1927\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.7500 - loss: 1.1115 - val_accuracy: 0.6071 - val_loss: 2.1661\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.7500 - loss: 1.0720 - val_accuracy: 0.6071 - val_loss: 2.1422\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.8095 - loss: 1.0342 - val_accuracy: 0.6071 - val_loss: 2.1152\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.8095 - loss: 0.9863 - val_accuracy: 0.6071 - val_loss: 2.0855\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.8214 - loss: 0.9214 - val_accuracy: 0.6071 - val_loss: 2.0547\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.8333 - loss: 0.9104 - val_accuracy: 0.6071 - val_loss: 2.0259\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.8333 - loss: 0.8589 - val_accuracy: 0.6071 - val_loss: 1.9921\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.8571 - loss: 0.8191 - val_accuracy: 0.6071 - val_loss: 1.9659\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.8452 - loss: 0.7873 - val_accuracy: 0.6071 - val_loss: 1.9323\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.8690 - loss: 0.7263 - val_accuracy: 0.6071 - val_loss: 1.9075\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8690 - loss: 0.6818 - val_accuracy: 0.6071 - val_loss: 1.8842\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9048 - loss: 0.6545 - val_accuracy: 0.6071 - val_loss: 1.8694\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 0.9167 - loss: 0.6151 - val_accuracy: 0.6071 - val_loss: 1.8592\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9167 - loss: 0.5920 - val_accuracy: 0.6071 - val_loss: 1.8530\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9167 - loss: 0.5461 - val_accuracy: 0.6071 - val_loss: 1.8455\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9048 - loss: 0.5304 - val_accuracy: 0.6071 - val_loss: 1.8312\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9286 - loss: 0.4930 - val_accuracy: 0.6071 - val_loss: 1.8161\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9524 - loss: 0.4719 - val_accuracy: 0.6071 - val_loss: 1.7996\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9643 - loss: 0.4608 - val_accuracy: 0.6071 - val_loss: 1.7919\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9524 - loss: 0.4324 - val_accuracy: 0.6429 - val_loss: 1.7736\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737ms/step - accuracy: 0.9524 - loss: 0.3931 - val_accuracy: 0.6429 - val_loss: 1.7570\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420ms/step - accuracy: 0.9762 - loss: 0.3792 - val_accuracy: 0.6429 - val_loss: 1.7447\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.9643 - loss: 0.3397 - val_accuracy: 0.6429 - val_loss: 1.7256\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443ms/step - accuracy: 0.9881 - loss: 0.3194 - val_accuracy: 0.6786 - val_loss: 1.7058\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.9881 - loss: 0.3031 - val_accuracy: 0.7143 - val_loss: 1.6935\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step - accuracy: 0.9881 - loss: 0.3065 - val_accuracy: 0.6786 - val_loss: 1.6925\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9881 - loss: 0.2709 - val_accuracy: 0.6786 - val_loss: 1.6930\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.2497 - val_accuracy: 0.6786 - val_loss: 1.6935\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.2424 - val_accuracy: 0.6786 - val_loss: 1.6959\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.2278 - val_accuracy: 0.6786 - val_loss: 1.6945\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 1.0000 - loss: 0.2179 - val_accuracy: 0.6786 - val_loss: 1.6914\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 0.2031 - val_accuracy: 0.6786 - val_loss: 1.6805\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.1914 - val_accuracy: 0.6786 - val_loss: 1.6700\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.1922 - val_accuracy: 0.6786 - val_loss: 1.6632\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.1687 - val_accuracy: 0.6786 - val_loss: 1.6578\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 1.0000 - loss: 0.1539 - val_accuracy: 0.7143 - val_loss: 1.6537\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 1.0000 - loss: 0.1528 - val_accuracy: 0.7143 - val_loss: 1.6487\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.1430 - val_accuracy: 0.7143 - val_loss: 1.6444\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 1.0000 - loss: 0.1388 - val_accuracy: 0.7143 - val_loss: 1.6422\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 1.0000 - loss: 0.1291 - val_accuracy: 0.7143 - val_loss: 1.6416\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.1167 - val_accuracy: 0.7143 - val_loss: 1.6403\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.1066 - val_accuracy: 0.7143 - val_loss: 1.6387\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 1.0000 - loss: 0.0924 - val_accuracy: 0.7143 - val_loss: 1.6361\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.1040 - val_accuracy: 0.7143 - val_loss: 1.6327\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0953 - val_accuracy: 0.7143 - val_loss: 1.6308\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0904 - val_accuracy: 0.7143 - val_loss: 1.6288\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0862 - val_accuracy: 0.7143 - val_loss: 1.6289\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0896 - val_accuracy: 0.7143 - val_loss: 1.6282\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0856 - val_accuracy: 0.7143 - val_loss: 1.6272\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0742 - val_accuracy: 0.7143 - val_loss: 1.6255\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 1.0000 - loss: 0.0746 - val_accuracy: 0.7143 - val_loss: 1.6251\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 1.0000 - loss: 0.0660 - val_accuracy: 0.7143 - val_loss: 1.6234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ff415093250>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#recustruction text"
      ],
      "metadata": {
        "id": "T6eegl6M2uwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, tokenizer, model, max_len):\n",
        "    sequence = tokenizer.texts_to_sequences([seed_text])\n",
        "    sequence = pad_sequences(sequence, maxlen=max_len, padding='post')\n",
        "    pred = model.predict([sequence, sequence])\n",
        "    generated_text = ''.join([tokenizer.index_word.get(np.argmax(word), '') for word in pred[0]])\n",
        "    return generated_text\n",
        "\n"
      ],
      "metadata": {
        "id": "vKSFq_CM2uEY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# testing model"
      ],
      "metadata": {
        "id": "rlIyxk6D6Rco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"عجم زنده کردم بدین پارسی\"\n",
        "output_text = generate_text(test_text, tokenizer, model, max_len)\n",
        "print(\"constructed text: \", output_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Pydlqu6UK7",
        "outputId": "afb04d31-8647-4dec-d95b-8608c82c660d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "constructed text:  عجم زنده کردم بدین پارسی\n"
          ]
        }
      ]
    }
  ]
}