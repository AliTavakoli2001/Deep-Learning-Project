{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliTavakoli2001/Deep-Learning-Project/blob/main/Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add the necessary Frameworks and Libraries**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VCjWISbC6B1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as TF\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as NP\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Rb3PoTmy7Eoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Load Mnist Data**\n",
        "\n",
        "\n",
        "> **Why unlabeled data?**\n",
        "\n",
        "In an autoencoder, we only need unlabeled data because it is an unsupervised learning model. The goal of an autoencoder is to learn the underlying patterns of the data and reconstruct the input data without requiring any labels. It focuses on minimizing the reconstruction error rather than predicting labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xAfV4_Nv-oOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ZHUMUl7Wg3",
        "outputId": "a558d345-b6f3-42c2-fcc3-7cce0d393cf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Normalize data to range [0,1]**\n",
        "\n",
        "\n",
        "> **Normalizing Image Data for Better Model Performance**\n",
        "\n",
        "The two lines of code normalize the image data by converting pixel values from the range [0, 255] to [0, 1]. This is done by first converting the data type to float32 and then dividing by 255. This normalization helps improve model performance and training stability by ensuring the input features are on a similar scale.\n",
        "\n"
      ],
      "metadata": {
        "id": "vmPbXEdzCaLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "5j0FSOZRCqEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# Flatten images\n",
        "\n",
        "The `reshape` function converts each 2D image into a 1D vectorby flattening the pixel values row-wise. This transformation is necessary because fully connected neural networks expect 1D input vectors instead of 2D matrices."
      ],
      "metadata": {
        "id": "9G7Fe9UdtVfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "x_test = x_test.reshape((len(x_test), -1))"
      ],
      "metadata": {
        "id": "8JhxXlbitjOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Define Autoencoder model\n",
        "\n",
        "\n",
        "1. The input layer `Input(shape=(784,))` takes a **flattened 28×28 image** as a **1D vector** with **784 values**.  \n",
        "2. The **encoder layer** `Dense(32, activation='relu')` reduces the input **from 784 to 32 dimensions**, extracting key features.  \n",
        "3. The **decoder layer** `Dense(784, activation='sigmoid')` reconstructs the original **784-dimensional** image from the **compressed 32-dimensional** representation.  \n",
        "4. **ReLU** helps retain important features in encoding, while **sigmoid** ensures output values remain between **0 and 1**, matching the normalized pixel range.  "
      ],
      "metadata": {
        "id": "DOXT8hqDtpJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_dim = 32\n",
        "\n",
        "input_img = Input(shape=(784,))\n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "metadata": {
        "id": "lmf9MI9Dtqfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# model summary\n",
        "\n",
        "This will show the architecture and the number of parameters"
      ],
      "metadata": {
        "id": "mlKBGopyOI4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "CaAmya1HOP0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Compile model\n",
        "\n",
        "This line compiles the autoencoder using the **Adam optimizer** for efficient and adaptive learning and **binary cross-entropy loss**, which is suitable for pixel values (0 to 1) and helps minimize reconstruction error."
      ],
      "metadata": {
        "id": "VcQ9aLaWtzoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Bs3NZ9sct2Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Train the autoencoder\n",
        "This line trains the autoencoder model for 50 epochs using the training data (x_train) as both input and target. It processes data in batches of 256, shuffling the data before each epoch. The validation data (x_test) is used to track performance during training, and a progress bar is shown during training with verbose=1. The training history, including loss and accuracy, is saved in the history variable."
      ],
      "metadata": {
        "id": "CS4dlrZxt7fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test), verbose=1)"
      ],
      "metadata": {
        "id": "bpzXUaggt47c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Visualizing the results\n",
        "\n",
        "This function displays images from the **original test data** and the **reconstructed images** generated by the autoencoder model in a two-row plot. The first row shows the original images, and the second row shows the reconstructed images from the model. This helps you evaluate the model's performance in terms of image reconstruction."
      ],
      "metadata": {
        "id": "LPGLu9g-vPx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(x_test, decoded_imgs, n=10):\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-SMIK-SOvM5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Encode and decode some test images\n",
        "\n",
        "This line of code uses the `autoencoder` model to make **predictions** on the input test data (`x_test`). It generates **reconstructed images** that should closely resemble the original test images, though with some potential minor loss or distortion. The reconstructed images are stored in the `decoded_imgs` variable."
      ],
      "metadata": {
        "id": "PzXAqJ6gvJxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)"
      ],
      "metadata": {
        "id": "yAhtZ_ODt_bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Plot the results"
      ],
      "metadata": {
        "id": "tGEEOLBGRIcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(x_test, decoded_imgs)\n"
      ],
      "metadata": {
        "id": "5ZTd26X3RO4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "\n",
        "This code plots the **model's accuracy** over training and validation datasets throughout the epochs. It visualizes the accuracy on the training data (`Train`) and the validation data (`Test`) over the course of training, with labeled axes for epochs and accuracy. The chart helps track the model's performance and improvement during training."
      ],
      "metadata": {
        "id": "Bof1zJr4RTix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9WdC5ejkR8PZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}